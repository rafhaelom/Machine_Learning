{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aprendizagem_spaCy_to_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11pxjoIHP1vp"
      },
      "source": [
        "# Sobre o curso\n",
        "spaCy é uma biblioteca moderna em Python para Processamento de Linguagem Natural (PLN) em escala profissional. Neste curso online, gratuito e interativo, você aprenderá a utilizar a biblioteca spaCy para construir sistemas avançados de entendimento de linguagem natural, usando tanto estratégias baseadas em regras como aprendizado de máquina.\n",
        "\n",
        "Site do curso: https://course.spacy.io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fs9x0llyFsQJ"
      },
      "source": [
        "# Capítulo 1: Selecionando palavras, frases, nomes e alguns conceitos\n",
        "Neste capítulo vamos apresentar os conceitos básicos de processamento de texto utilizando a biblioteca spaCy. Você vai aprender sobre as estruturas de dados, como trabalhar com modelos estatísticos e como usá-los para prever anotações linguísticas do seu texto.\n",
        "\n",
        "## 1.1 - Introdução da Biblioteca spaCy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nitkOXTo_KcN"
      },
      "source": [
        "# Importando Bibliotecas.\n",
        "\n",
        "# O objeto nlp\n",
        "#Importando classe para a longua inglesa.\n",
        "from spacy.lang.en import English\n",
        "\n",
        "# Criando objeto de nlp.\n",
        "nlp = English()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zm1Sh95_xjE",
        "outputId": "249fe536-94fd-453f-a477-a76cd791e65a"
      },
      "source": [
        "# O objeto Doc\n",
        "# Criado após processar um texto com o objeto nlp\n",
        "doc = nlp(\"Hello world!\")\n",
        "\n",
        "# Iterar nos tokens do Doc\n",
        "for token in doc:\n",
        "    print(token.text)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello\n",
            "world\n",
            "!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqft1LOw_0LL",
        "outputId": "0dd1453e-c778-4490-f77a-076030e74208"
      },
      "source": [
        "# Objeto token.\n",
        "# Indexar o Doc para obter um Token\n",
        "token = doc[1]\n",
        "\n",
        "# Obter o texto do token através do atributo .text\n",
        "print(token.text)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "world\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMoLk42y_0q0",
        "outputId": "7e1ab428-5a48-4f11-f35e-8de49b5b22f5"
      },
      "source": [
        "# O objeto Partição (Span)\n",
        "# Um pedaço do Doc é um objeto Partição (Span) \n",
        "span = doc[1:3]\n",
        "\n",
        "# Obter o texto da partição com o atributo .text\n",
        "print(span.text)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "world!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RffteL-z_03U",
        "outputId": "36706388-5116-4850-d924-872f1fdcc0b9"
      },
      "source": [
        "# Atributos léxicos\n",
        "doc = nlp(\"It costs $5.\")\n",
        "\n",
        "print(\"Index:   \", [token.i for token in doc])\n",
        "print(\"Text:    \", [token.text for token in doc])\n",
        "\n",
        "print(\"is_alpha:\", [token.is_alpha for token in doc])\n",
        "print(\"is_punct:\", [token.is_punct for token in doc])\n",
        "print(\"like_num:\", [token.like_num for token in doc])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index:    [0, 1, 2, 3, 4]\n",
            "Text:     ['It', 'costs', '$', '5', '.']\n",
            "is_alpha: [True, True, False, False, False]\n",
            "is_punct: [False, False, False, False, True]\n",
            "like_num: [False, False, False, True, False]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzF4m040F9oE"
      },
      "source": [
        "## 1.2 - Primeiros passos\n",
        "Vamos começar colocando a mão na massa! Neste exercício você fará experimentos com alguns dos mais de 55 idiomas disponíveis.\n",
        "\n",
        "https://spacy.io/usage/models#languages\n",
        "\n",
        "https://spacy.io/usage/models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Au0kTpJvGKmQ"
      },
      "source": [
        "Parte 1: Inglês\n",
        "Faça a importação da classe English da biblioteca spacy.lang.en e crie um objeto nlp.\n",
        "Crie uma variável doc e imprima o seu conteúdo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tx_-1o5_1By"
      },
      "source": [
        "# Importe a classe do idioma inglês\n",
        "from spacy.lang.en import English\n",
        "\n",
        "# Crie um objeto nlp\n",
        "nlp = English()\n",
        "\n",
        "# Processe o texto\n",
        "doc = nlp(\"This is a sentence.\")\n",
        "\n",
        "# Imprima o texto do documento\n",
        "print(doc.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OpFaZRfGOnk"
      },
      "source": [
        "Parte 2: Alemão\n",
        "Faça a importação da classe German da biblioteca spacy.lang.de e crie um objeto nlp.\n",
        "Crie uma variável doc e imprima o seu conteúdo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2DGBHvC_1rT"
      },
      "source": [
        "# Importe a classe do idioma alemão (German)\n",
        "from spacy.lang.de import German\n",
        "\n",
        "# Crie um objeto nlp\n",
        "nlp = German()\n",
        "\n",
        "# Processe o texto (equivalente ao português: \"Atenciosamente\")\n",
        "doc = nlp(\"Liebe Grüße!\")\n",
        "\n",
        "# Imprima o texto do documento\n",
        "print(doc.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKDuttQAGS74"
      },
      "source": [
        "Parte 3: Espanhol\n",
        "Faça a importação da classe Spanish da biblioteca spacy.lang.es e crie um objeto nlp.\n",
        "Crie uma variável doc e imprima o seu conteúdo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_kZ-5EM_102"
      },
      "source": [
        "# Importar a classe da língua espanhola (Spanish) \n",
        "from spacy.lang.es import Spanish\n",
        "\n",
        "# Crie um objeto nlp\n",
        "nlp = Spanish()\n",
        "\n",
        "# Processar o texto em espanhol (equivalente ao português: \"Como vai?\")\n",
        "doc = nlp(\"¿Cómo estás?\")\n",
        "\n",
        "# Imprimir o texto do documento\n",
        "print(doc.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pud1vLJdGc-J"
      },
      "source": [
        "## 1.3 - Documentos, partições e tokens\n",
        "\n",
        "Quando você chama o objeto nlp passando uma string como parâmetro, a spaCy faz a toquenização do texto e cria um objeto do tipo documento. Neste exercício, você vai aprender mais sobre o documento Doc, assim como os objetos Token e partição Span.\n",
        "\n",
        "Passo 1\n",
        "Faça a importação da classe English e crie um objeto nlp.\n",
        "Processe o texto e instancie um objeto Doc na variável doc.\n",
        "Selecione o primeiro token do objeto Doc e imprima seu texto text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4B_S5tBQ_19P"
      },
      "source": [
        "# Importar a classe da língua inglesa (English) e criar um objeto nlp\n",
        "from spacy.lang.en import English\n",
        "nlp = English()\n",
        "\n",
        "# Processar o texto\n",
        "doc = nlp(\"I like tree kangaroos and narwhals.\")\n",
        "\n",
        "# Selecionar o primeiro token\n",
        "first_token = doc[0]\n",
        "\n",
        "# Imprimir o texto do primeito token\n",
        "print(first_token.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tnsiYmIHc0O"
      },
      "source": [
        "Passo 2\n",
        "Faça a importação da classe English e crie um objeto nlp.\n",
        "Processe o texto e instancie um objeto Doc na variável doc.\n",
        "Crie uma partição do Doc para os tokens “tree kangaroos” e “tree kangaroos and narwhals”."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSVoVI7R_50i"
      },
      "source": [
        "# Importar a classe da língua inglesa (English) e criar um objeto nlp\n",
        "from spacy.lang.en import English\n",
        "\n",
        "nlp = English()\n",
        "\n",
        "# Processar o texto\n",
        "doc = nlp(\"I like tree kangaroos and narwhals.\")\n",
        "\n",
        "# Uma partição do Doc para \"tree kangaroos\"\n",
        "tree_kangaroos = doc[2:4]\n",
        "print(tree_kangaroos.text)\n",
        "\n",
        "# Uma partição do Doc para \"tree kangaroos and narwhals\" (sem incluir o \".\")\n",
        "tree_kangaroos_and_narwhals = doc[2:6]\n",
        "print(tree_kangaroos_and_narwhals.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xqg8wljYLAWZ"
      },
      "source": [
        "## 1.4 - Atributos léxicos\n",
        "\n",
        "Neste exemplo, você poderá usar os objetos Doc e Token combinados com atributos léxicos para encontrar referências de porcentagem em seu texto. Você irá procurar por dois elementos (tokens) sequenciais: um número e um sinal de porcentagem.\n",
        "\n",
        "Use o atributo like_num para identificar se algum token no documento doc se assemelha a um número.\n",
        "Selecione o token seguinte ao token atual no documento. O índice para o próximo token no doc é token.i + 1.\n",
        "Verifique se o atributo text do próximo token é o sinal de porcentagem ”%“."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUGfcBNJLGNj"
      },
      "source": [
        "from spacy.lang.en import English\n",
        "\n",
        "nlp = English()\n",
        "\n",
        "# Processar o texto\n",
        "doc = nlp(\n",
        "    \"In 1990, more than 60% of people in East Asia were in extreme poverty. \"\n",
        "    \"Now less than 4% are.\"\n",
        ")\n",
        "\n",
        "# Iterar os tokens de um documento doc\n",
        "for token in doc:\n",
        "    # Checar se o token é composto por algarismos numéricos\n",
        "    if token.like_num:\n",
        "        # Selecionar o próximo token do documento\n",
        "        next_token = doc[token.i + 1]\n",
        "        # Checar se o texto do proximo token é igual a \"%\"\n",
        "        if next_token.text == \"%\":\n",
        "            print(\"Percentage found:\", token.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEs1MJEgPwpk"
      },
      "source": [
        "## 1.5 - Modelos Estatísticos\n",
        "\n",
        "O que são modelos estatísticos?\n",
        "Permitem que a spaCy faça previsões de atributos linguísticos em contextos:\n",
        "Marcadores de classes gramaticais\n",
        "Dependências sintáticas\n",
        "Entidades nomeadas\n",
        "São treinados com exemplos de textos rotulados.\n",
        "Podem ser atualizados com mais exemplos para um ajuste fino das previsões."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whC8ZXRsLGHX"
      },
      "source": [
        "# Pacotes dos modelos\n",
        "# python -m spacy download en_core_web_sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQYEqjM5LGBB"
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnuhjF35LF4s",
        "outputId": "ce90e0d4-4010-4a7c-9dac-65d8e13d87ca"
      },
      "source": [
        "# Previsão dos marcadores de classe gramatical.\n",
        "import spacy\n",
        "\n",
        "# Carregar o modelo pequeno do Inglês\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Processar um texto\n",
        "doc = nlp(\"She ate the pizza\")\n",
        "\n",
        "# Iterar nos tokens\n",
        "for token in doc:\n",
        "    # Imprimir o texto e a classe gramatical prevista\n",
        "    print(token.text, token.pos_)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "She PRON\n",
            "ate VERB\n",
            "the DET\n",
            "pizza NOUN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZNs1TK1Z_UJ"
      },
      "source": [
        "# Previsão de termos sintáticos.\n",
        "for token in doc:\n",
        "    print(token.text, token.pos_, token.dep_, token.head.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8ABkbLJZ_so",
        "outputId": "b7f69941-19fd-44ee-8a2a-f1eefc5e4079"
      },
      "source": [
        "# Previsão de Entidades Nomeadas.\n",
        "\n",
        "# Processar um texto\n",
        "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "\n",
        "# Iterar nas entidades previstas\n",
        "for ent in doc.ents:\n",
        "    # Imprimir o texto da entidade e seu marcador\n",
        "    print(ent.text, ent.label_)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Apple ORG\n",
            "U.K. GPE\n",
            "$1 billion MONEY\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "digfLh1CaAHH",
        "outputId": "69556527-6d2f-45a9-f5e4-c1694e18ef36"
      },
      "source": [
        "# Dica: o método spacy.explain\n",
        "# Obtenha uma suscinta explicação dos marcadores mais comuns:\n",
        "\n",
        "spacy.explain(\"GPE\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Countries, cities, states'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hZmYmGNCb5A1",
        "outputId": "b2130b89-6e57-4776-cc0f-cca956dd725c"
      },
      "source": [
        "spacy.explain(\"NNP\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'noun, proper singular'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "58t2sZ9Kb5kt",
        "outputId": "46f19c10-f498-4d4e-998c-d32128c6a0c9"
      },
      "source": [
        "spacy.explain(\"dobj\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'direct object'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1lhjHAScScA"
      },
      "source": [
        "## 1.6 - Biblioteca dos modelos.\n",
        "\n",
        "O que NÃO está incluído nos modelos que você pode carregar na spaCy?\n",
        "\n",
        "Um arquivo com metadados do idioma, pipeline e licença.\n",
        "\n",
        "Pesos binários para efetuar as previsões estatísticas.\n",
        "\n",
        "Os dados nos quais o modelo foi treinado.\n",
        "\n",
        "O vocabulário do modelo e seus códigos indexadores (hashes).\n",
        "\n",
        "Enviar\n",
        "Correto! Os modelos estatísticos permitem a generalização a partir de um conjunto de exemplos de treinamento. Uma vez treinados, os modelos usam os pesos binários para fazer as previsões. É por este motivo que não é necessário que os dados de treinamento sejam incluídos nos modelos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWqybAzDcvbz"
      },
      "source": [
        "## 1.7 - Carregando os modelos.\n",
        "\n",
        "Os modelos que estamos usando neste treinamento já vem pré-instalados. Para saber mais informações sobre os modelos estatísticos e como instalá-los em seu computador, consulte essa documentação.\n",
        "\n",
        "https://spacy.io/usage/models\n",
        "\n",
        "Utilize spacy.load para carregar o modelo pequeno da língua inglesa \"en_core_web_sm\".\n",
        "Processe o texto e imprima o texto do documento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bmllP8Pb5e5"
      },
      "source": [
        "import spacy\n",
        "\n",
        "# Carregue o modelo pequeno do idioma inglês \"en_core_web_sm\"\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\"\n",
        "\n",
        "# Processe o texto\n",
        "doc = nlp(text)\n",
        "\n",
        "# Imprima o atributo texto do documento\n",
        "print(doc.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FoZdWbGfRaX"
      },
      "source": [
        "## 1.8 - Prevendo anotações linguísticas.\n",
        "\n",
        "Agora vamos experimentar um dos modelos pré-treinados da spaCy e ver o resultado de sua previsão. Fique à vontade e experimente com seu próprio texto! Use spacy.explain para saber o significado de um determinado marcador. Por exemplo: spacy.explain(\"PROPN\") ou spacy.explain(\"GPE\").\n",
        "\n",
        "Parte 1\n",
        "Processe o texto utilizando o objeto nlp e crie um doc.\n",
        "Para cada token, imprima seu texto, sua classe gramatical .pos_ e seu termo sintático .dep_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIMQHVBtb5Y0"
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\"\n",
        "\n",
        "# Processar o texto\n",
        "doc = nlp(text)\n",
        "\n",
        "for token in doc:\n",
        "    # Selecionar o texto, s classe gramatical e o termo sintático de um token\n",
        "    token_text = token.text\n",
        "    token_pos = token.pos_\n",
        "    token_dep = token.dep_\n",
        "    # Para uma boa formatação da impressão\n",
        "    print(f\"{token_text:<12}{token_pos:<10}{token_dep:<10}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFQZUuOWiOON"
      },
      "source": [
        "Parte 2\n",
        "Processe o texto utilizando o objeto nlp e crie um doc.\n",
        "Construa uma iteração em doc.ents e imprima os atributos texto e o marcador label_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa7ZHq6viPJ8"
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\"\n",
        "\n",
        "# Process the text\n",
        "doc = nlp(text)\n",
        "\n",
        "# Iterar nas entidades previstas\n",
        "for ent in doc.ents:\n",
        "    # Imprimir o texto e a etiqueta da entidade\n",
        "    print(ent.text, ent.label_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTtMcDwFjleI"
      },
      "source": [
        "## 1.9 - Prevendo Entidades em um contexto.\n",
        "\n",
        "Os modelos são estatísticos e por isso não acertam 100% dos casos. A acurácia do modelo depende dos dados nos quais o modelo foi treinado e também dos dados que você está processando. Vamos ver um exemplo:\n",
        "\n",
        "Processe o texto utilizando o objeto nlp.\n",
        "Construa uma iteração nas entidades e imprima o texto e o marcador (label) da entidade.\n",
        "Note que o modelo não previu “iPhone X”. Crie manualmente uma partição para esses tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIn2LV-fiPqg"
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"Upcoming iPhone X release date leaked as Apple reveals pre-orders\"\n",
        "\n",
        "# Processar o texto\n",
        "doc = nlp(text)\n",
        "\n",
        "# Iterar nas entidades previstas\n",
        "for ent in doc.ents:\n",
        "    # Print the entity text and label\n",
        "    print(ent.text, ent.label_)\n",
        "\n",
        "# Selecionar a partição para \"iPhone X\"\n",
        "iphone_x = doc[1:3]\n",
        "\n",
        "# Imprimir o texto da partição\n",
        "print(\"Missing entity:\", iphone_x.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPDzTlhvlpD-"
      },
      "source": [
        "## 1.10 - Correspondência de texto baseada em regras.\n",
        "\n",
        "Por que usar o Comparador e não somente expressões regulares?\n",
        "Compara com objetos Doc e não apenas texto (strings)\n",
        "Compara com os tokens e seus atributos\n",
        "Utiliza a previsão do modelo\n",
        "Exemplo: \"duck\" (verbo) vs. \"duck\" (substantivo)\n",
        "\n",
        "Por que usar o Comparador e não somente expressões regulares?\n",
        "Compara com objetos Doc e não apenas texto (strings)\n",
        "Compara com os tokens e seus atributos\n",
        "Utiliza a previsão do modelo\n",
        "Exemplo: \"duck\" (verbo) vs. \"duck\" (substantivo)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfzfXs5_iPlP"
      },
      "source": [
        "# Expressões de correspondência\n",
        "# Listas de dicionários, uma por token\n",
        "\n",
        "# Corresponde exatamente ao texto de um token:\n",
        "[{\"TEXT\": \"iPhone\"}, {\"TEXT\": \"X\"}]\n",
        "\n",
        "# Corresponde a atributos léxicos:\n",
        "[{\"LOWER\": \"iphone\"}, {\"LOWER\": \"x\"}]\n",
        "\n",
        "# Corresponde a qualquer atributo de um token:\n",
        "[{\"LEMMA\": \"buy\"}, {\"POS\": \"NOUN\"}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNYzZku4iPg2"
      },
      "source": [
        "# Usando o Comparador (Matcher) (1)\n",
        "import spacy\n",
        "\n",
        "# Importar o Comparador (Matcher)\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "# Carregar o modelo e criar um objeto nlp\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Inicializar o comparador com o vocabulário \n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Adicionar a expressão ao comparador\n",
        "pattern = [{\"TEXT\": \"iPhone\"}, {\"TEXT\": \"X\"}]\n",
        "matcher.add(\"IPHONE_PATTERN\", None, pattern)\n",
        "\n",
        "# Processar um texto\n",
        "doc = nlp(\"Upcoming iPhone X release date leaked\")\n",
        "\n",
        "# Chamar o matcher no doc\n",
        "matches = matcher(doc)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mgxi-EQ67Mvs",
        "outputId": "81aa3b33-8b81-4bb0-aa58-34b8fe6be2ee"
      },
      "source": [
        "# Usando o Comparador (Matcher) (2)\n",
        "# Chamar o comparador e passar o texto\n",
        "doc = nlp(\"Upcoming iPhone X release date leaked\")\n",
        "matches = matcher(doc)\n",
        "\n",
        "# Iterar nas correspondências\n",
        "for match_id, start, end in matches:\n",
        "    # Selecionar a partição que houve correspondência\n",
        "    matched_span = doc[start:end]\n",
        "    print(matched_span.text)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iPhone X\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEHYvIx8H3I_"
      },
      "source": [
        "match_id: código hash da expressão\n",
        "start: índice inicial da partição em que houve correspondência\n",
        "end: índice final da partição em que houve correspondência"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhbCczL97Mrg"
      },
      "source": [
        "# Expressões com atributos léxicos\n",
        "pattern = [\n",
        "    {\"IS_DIGIT\": True},\n",
        "    {\"LOWER\": \"fifa\"},\n",
        "    {\"LOWER\": \"world\"},\n",
        "    {\"LOWER\": \"cup\"},\n",
        "    {\"IS_PUNCT\": True}\n",
        "]\n",
        "\n",
        "doc = nlp(\"2018 FIFA World Cup: France won!\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWSKPX_57Mn1"
      },
      "source": [
        "# Expressões com outros atributos dos tokens\n",
        "pattern = [\n",
        "    {\"LEMMA\": \"love\", \"POS\": \"VERB\"},\n",
        "    {\"POS\": \"NOUN\"}\n",
        "]\n",
        "doc = nlp(\"I loved dogs but now I love cats more.\")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsOvYx0i7MjW"
      },
      "source": [
        "# Utilizando operadores e quantificadores (1)\n",
        "pattern = [\n",
        "    {\"LEMMA\": \"buy\"},\n",
        "    {\"POS\": \"DET\", \"OP\": \"?\"},  # opcional: corresponde a 0 ou 1 vez\n",
        "    {\"POS\": \"NOUN\"}\n",
        "]\n",
        "doc = nlp(\"I bought a smartphone. Now I'm buying apps.\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwhHtzXcJg07"
      },
      "source": [
        "Utilizando operadores e quantificadores (2)\n",
        "Exemplo\tDescrição\n",
        "{\"OP\": \"!\"}\tNegação: corresponde 1 vez\n",
        "{\"OP\": \"?\"}\tOpcional: corresponde 0 ou 1 vez\n",
        "{\"OP\": \"+\"}\tCorresponde 1 ou mais vezes\n",
        "{\"OP\": \"*\"}\tCorresponde 1 ou mais vezes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fA23TWKJJyWZ"
      },
      "source": [
        "## 1.11 - Usando o comparador Matcher.\n",
        "\n",
        "Vamos agora testar o comparador de expressões Matcher baseado em regras. Você vai usar o exemplo do exercício anterior e escrever uma expressão que faça a correspondência para a frase “iPhone X” no texto.\n",
        "\n",
        "Importe o Matcher de spacy.matcher.\n",
        "Inicialize o comparador com o objeto compartilhado vocabdo nlp.\n",
        "Crie uma expressão que faça a correspondência dos valores em \"TEXT\" para dois tokens: \"iPhone\" e \"X\".\n",
        "Use o método matcher.add e adicione essa expressão ao comparador.\n",
        "Chame o comparador passando como parâmetro o doc e armazene o resultado na variável matches.\n",
        "Itere nos resultados e selecione a partição de texto com o índice start até end."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urDk0OUd7McT",
        "outputId": "71241498-488f-4d29-e27d-31dea267ba7c"
      },
      "source": [
        "import spacy\n",
        "\n",
        "# Importe o comparador - Matcher\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Upcoming iPhone X release date leaked as Apple reveals pre-orders\")\n",
        "\n",
        "# Inicialize o comparador com o vocabulário compartilhado \n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Crie uma expressão que faça a correspondência dos tokens: \"iPhone\" and \"X\"\n",
        "pattern = [{\"TEXT\": \"iPhone\"}, {\"TEXT\": \"X\"}]\n",
        "\n",
        "# Adicione uma expressão ao comparador\n",
        "matcher.add(\"IPHONE_X_PATTERN\", None, pattern)\n",
        "\n",
        "# Use o comparador no doc\n",
        "matches = matcher(doc)\n",
        "print(\"Matches:\", [doc[start:end].text for match_id, start, end in matches])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matches: ['iPhone X']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJZBpyQ8L0YY"
      },
      "source": [
        "## 1.12 - Escrevendo expressões de correspondência.\n",
        "\n",
        "Neste exercício, você vai escrever algumas expressões mais complexas de correspondência, usando os atributos dos tokens e operadores.\n",
        "\n",
        "Parte 1\n",
        "Escreva uma expressão que corresponda às menções da versão IOS completa: “iOS 7”, “iOS 11” e “iOS 10”."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-zprsZpLuN5"
      },
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "doc = nlp(\n",
        "    \"After making the iOS update you won't notice a radical system-wide \"\n",
        "    \"redesign: nothing like the aesthetic upheaval we got with iOS 7. Most of \"\n",
        "    \"iOS 11's furniture remains the same as in iOS 10. But you will discover \"\n",
        "    \"some tweaks once you delve a little deeper.\"\n",
        ")\n",
        "\n",
        "# Escreva uma expressão que corresponda às versões completas do IOS (\"iOS 7\", \"iOS 11\", \"iOS 10\")\n",
        "pattern = [{\"TEXT\": \"iOS\"}, {\"IS_DIGIT\": True}]\n",
        "\n",
        "# Adicione a expressão ao comparador matcher e aplique o matcher ao doc\n",
        "matcher.add(\"IOS_VERSION_PATTERN\", None, pattern)\n",
        "matches = matcher(doc)\n",
        "print(\"Total matches found:\", len(matches))\n",
        "\n",
        "# Faça a iteração sobre as correspondencias e imprima a partição do texto\n",
        "for match_id, start, end in matches:\n",
        "    print(\"Match found:\", doc[start:end].text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qhAi24ONRc-"
      },
      "source": [
        "Parte 2\n",
        "Escreva uma expressão que corresponda às variações de “download” (tokens que tenham “download” como lema), seguido de um token da classe gramatical substativo próprio \"PROPN\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fa__KukcLuKH",
        "outputId": "10e65d21-3532-475e-e659-edd0a8a8ee5f"
      },
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "doc = nlp(\n",
        "    \"i downloaded Fortnite on my laptop and can't open the game at all. Help? \"\n",
        "    \"so when I was downloading Minecraft, I got the Windows version where it \"\n",
        "    \"is the '.zip' folder and I used the default program to unpack it... do \"\n",
        "    \"I also need to download Winzip?\"\n",
        ")\n",
        "\n",
        "# Escreva uma expressão que corresponda às variações de \"download\" seguido de um\n",
        "# substatantivo próprio\n",
        "pattern = [{\"LEMMA\": \"download\"}, {\"POS\": \"PROPN\"}]\n",
        "\n",
        "# Adicione a expressão ao comparador matcher e aplique o matcher ao doc\n",
        "matcher.add(\"DOWNLOAD_THINGS_PATTERN\", None, pattern)\n",
        "matches = matcher(doc)\n",
        "print(\"Total matches found:\", len(matches))\n",
        "\n",
        "# Faça a iteração nas correspondências e imprima a partição do texto\n",
        "for match_id, start, end in matches:\n",
        "    print(\"Match found:\", doc[start:end].text)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total matches found: 3\n",
            "Match found: downloaded Fortnite\n",
            "Match found: downloading Minecraft\n",
            "Match found: download Winzip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUbeGVmEODeC"
      },
      "source": [
        "Part 3\n",
        "Escreva uma expressão que corresponda a adjetivos (\"ADJ\") seguidos por um ou dois substantivos. (um substantivo obrigatório e um seguinte opcional)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jdzp6uNKLuGQ",
        "outputId": "e761e7a1-141a-4911-8482-f183920221b0"
      },
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "doc = nlp(\n",
        "    \"Features of the app include a beautiful design, smart search, automatic \"\n",
        "    \"labels and optional voice responses.\"\n",
        ")\n",
        "\n",
        "# Escreva uma expressão que corresponda a um adjetivo seguido de um ou dois substantivos\n",
        "pattern = [{\"POS\": \"ADJ\"}, {\"POS\": \"NOUN\"}, {\"POS\": \"NOUN\", \"OP\": \"?\"}]\n",
        "\n",
        "# Adicione uma expressão ao comparador matcher e aplique o matcher ao doc\n",
        "matcher.add(\"ADJ_NOUN_PATTERN\", None, pattern)\n",
        "matches = matcher(doc)\n",
        "print(\"Total matches found:\", len(matches))\n",
        "\n",
        "# Faça a iteração sobre as correspondencias e imprima a partição do texto\n",
        "for match_id, start, end in matches:\n",
        "    print(\"Match found:\", doc[start:end].text)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total matches found: 5\n",
            "Match found: beautiful design\n",
            "Match found: smart search\n",
            "Match found: automatic labels\n",
            "Match found: optional voice\n",
            "Match found: optional voice responses\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}